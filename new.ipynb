{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a base neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNeuralNetwork, self).__init__()\n",
    "        # Flatten inputs\n",
    "        #self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(26,416), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = BaseNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNeuralNetwork, self).__init__()\n",
    "        # Flatten inputs\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28 * 28, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512,256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256,128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64,32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16,10)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = BaseNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, prin = False):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation (always in three steps)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0 and prin:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "    return 100*(1-correct)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-----------------\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.563955\n",
      "Epoch 2-----------------\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.470518\n",
      "Epoch 3-----------------\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.433033\n",
      "Epoch 4-----------------\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.406194\n",
      "Epoch 5-----------------\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.389415\n",
      "Epoch 6-----------------\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.375461\n",
      "Epoch 7-----------------\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.370210\n",
      "Epoch 8-----------------\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.382567\n",
      "Epoch 9-----------------\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.367546\n",
      "Epoch 10-----------------\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.360022\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "error = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}-----------------\")\n",
    "    #Use train_loop and test_loop functions\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    x = test_loop(test_dataloader, model, loss_fn)\n",
    "    error.append(x)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNeuralNetworkRS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNeuralNetworkRS, self).__init__()\n",
    "        # Flatten inputs\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.start = nn.Linear(28 * 28, 512)\n",
    "        self.lin1 = nn.Linear(512,256)\n",
    "        self.lin2 = nn.Linear(256,128)\n",
    "        self.lin3 = nn.Linear(128,64)\n",
    "        self.lin4 = nn.Linear(64,32)\n",
    "        self.lin5 = nn.Linear(32,16)\n",
    "        self.fc = nn.Linear(16,10)\n",
    "        \n",
    "    def proj(self, x, size):\n",
    "        indice = np.linspace(0, size - 1, size).tolist()\n",
    "        indice = torch.tensor([int(x) for x in indice])\n",
    "        \n",
    "        return torch.index_select(x, 1, indice)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        f = 0\n",
    "        x = self.relu(self.start(x)) + f*self.proj(x, 512)\n",
    "        x = self.relu(self.lin1(x)) + f*self.proj(x, 256)\n",
    "        x = self.relu(self.lin2(x)) + f*self.proj(x, 128)\n",
    "        x = self.relu(self.lin3(x)) + f*self.proj(x, 64)\n",
    "        x = self.relu(self.lin4(x)) + f*self.proj(x, 32)\n",
    "        x = self.relu(self.lin5(x)) + f*self.proj(x, 16)\n",
    "        x = self.relu(self.fc(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "modelRS = BaseNeuralNetworkRS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 2-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 3-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 4-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 5-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 6-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 7-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 8-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 9-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Epoch 10-----------------\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.782022\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "error = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}-----------------\")\n",
    "    #Use train_loop and test_loop functions\n",
    "    train_loop(train_dataloader, modelRS, loss_fn, optimizer)\n",
    "    x = test_loop(test_dataloader, model, loss_fn)\n",
    "    error.append(x)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.750000000000007, 17.830000000000002, 15.239999999999998, 14.459999999999996, 14.359999999999996, 13.81, 13.770000000000005, 13.090000000000002, 12.9, 12.490000000000002]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "error_wo = copy.deepcopy(error)\n",
    "\n",
    "plt.plot(error_wo, label = \"w/o RS\")\n",
    "plt.legend()\n",
    "plt.title(\"% error per batch\")\n",
    "plt.ylim((0, 40))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten() # Flatten inputs\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                           \n",
    "            nn.Conv2d(\n",
    "                in_channels=16,              \n",
    "                out_channels=32,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2, ),     \n",
    "            nn.ReLU(),                                     \n",
    "        )\n",
    "\n",
    "        self.output_stack = nn.Sequential(\n",
    "            nn.Linear(32 * 28 * 28, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.conv_stack(x) \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        logits = logits.view(logits.size(0), -1)\n",
    "        logits = self.output_stack(logits)\n",
    "        return logits\n",
    "\n",
    "model = BaseNeuralNetwork()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-----------------\n",
      "loss: 2.300387  [    0/60000]\n",
      "loss: 0.330322  [25600/60000]\n",
      "loss: 0.329241  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.345539\n",
      "Epoch 2-----------------\n",
      "loss: 0.275289  [    0/60000]\n",
      "loss: 0.269909  [25600/60000]\n",
      "loss: 0.243078  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.302817\n",
      "Epoch 3-----------------\n",
      "loss: 0.185699  [    0/60000]\n",
      "loss: 0.232983  [25600/60000]\n",
      "loss: 0.192686  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.286924\n",
      "Epoch 4-----------------\n",
      "loss: 0.135113  [    0/60000]\n",
      "loss: 0.203886  [25600/60000]\n",
      "loss: 0.151900  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.279495\n",
      "Epoch 5-----------------\n",
      "loss: 0.100060  [    0/60000]\n",
      "loss: 0.186171  [25600/60000]\n",
      "loss: 0.126516  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.279829\n",
      "Epoch 6-----------------\n",
      "loss: 0.080773  [    0/60000]\n",
      "loss: 0.170438  [25600/60000]\n",
      "loss: 0.110165  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.287763\n",
      "Epoch 7-----------------\n",
      "loss: 0.068867  [    0/60000]\n",
      "loss: 0.153841  [25600/60000]\n",
      "loss: 0.110740  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.291258\n",
      "Epoch 8-----------------\n",
      "loss: 0.057316  [    0/60000]\n",
      "loss: 0.141716  [25600/60000]\n",
      "loss: 0.102374  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.293854\n",
      "Epoch 9-----------------\n",
      "loss: 0.048601  [    0/60000]\n",
      "loss: 0.133485  [25600/60000]\n",
      "loss: 0.086467  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.296571\n",
      "Epoch 10-----------------\n",
      "loss: 0.043056  [    0/60000]\n",
      "loss: 0.128555  [25600/60000]\n",
      "loss: 0.082706  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.302989\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "error_wo = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}-----------------\")\n",
    "    #Use train_loop and test_loop functions\n",
    "    learning_rate = 0.01/(t+1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, prin = True)\n",
    "    x = test_loop(test_dataloader, model, loss_fn)\n",
    "    error_wo.append(x)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying RS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten() # Flatten inputs\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                           \n",
    "            nn.Conv2d(\n",
    "                in_channels=16,              \n",
    "                out_channels=32,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2, ),                                     \n",
    "        )\n",
    "\n",
    "        self.output_stack = nn.Sequential(\n",
    "            nn.Linear(32 * 28 * 28, 10)\n",
    "        )\n",
    "\n",
    "    def proj(self, x, size):\n",
    "        indice = np.linspace(0, size - 1, size).tolist()\n",
    "        indice = torch.tensor([int(x) for x in indice])\n",
    "        res = torch.index_select(x, 3, indice)\n",
    "        res = torch.index_select(res, 2, indice)\n",
    "        return res\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "\n",
    "        logits = self.conv_stack(x) + x\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        logits = logits.view(logits.size(0), -1)\n",
    "        logits = self.output_stack(logits)\n",
    "        return logits\n",
    "\n",
    "model = BaseNeuralNetwork()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-----------------\n",
      "loss: 2.379060  [    0/60000]\n",
      "loss: 0.907272  [25600/60000]\n",
      "loss: 0.694651  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.789519\n",
      "Epoch 2-----------------\n",
      "loss: 0.750633  [    0/60000]\n",
      "loss: 0.637622  [25600/60000]\n",
      "loss: 0.648334  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.613266\n",
      "Epoch 3-----------------\n",
      "loss: 0.528052  [    0/60000]\n",
      "loss: 0.550186  [25600/60000]\n",
      "loss: 0.403670  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.479370\n",
      "Epoch 4-----------------\n",
      "loss: 0.336317  [    0/60000]\n",
      "loss: 0.372423  [25600/60000]\n",
      "loss: 0.287402  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.398178\n",
      "Epoch 5-----------------\n",
      "loss: 0.226613  [    0/60000]\n",
      "loss: 0.267910  [25600/60000]\n",
      "loss: 0.272990  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.405756\n",
      "Epoch 6-----------------\n",
      "loss: 0.201502  [    0/60000]\n",
      "loss: 0.245829  [25600/60000]\n",
      "loss: 0.281266  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.385216\n",
      "Epoch 7-----------------\n",
      "loss: 0.152557  [    0/60000]\n",
      "loss: 0.227615  [25600/60000]\n",
      "loss: 0.206704  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.379078\n",
      "Epoch 8-----------------\n",
      "loss: 0.137445  [    0/60000]\n",
      "loss: 0.213937  [25600/60000]\n",
      "loss: 0.181733  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.361322\n",
      "Epoch 9-----------------\n",
      "loss: 0.100978  [    0/60000]\n",
      "loss: 0.200710  [25600/60000]\n",
      "loss: 0.176762  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.367831\n",
      "Epoch 10-----------------\n",
      "loss: 0.086053  [    0/60000]\n",
      "loss: 0.187592  [25600/60000]\n",
      "loss: 0.163442  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.375745\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "error_w = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}-----------------\")\n",
    "    #Use train_loop and test_loop functions\n",
    "    learning_rate = 0.01/(t+1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, prin = True)\n",
    "    x = test_loop(test_dataloader, model, loss_fn)\n",
    "    error_w.append(x)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_w = copy.deepcopy(error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error_wo, label = \"w/o RS\")\n",
    "plt.plot(error_w, label = \"w RS\")\n",
    "plt.legend()\n",
    "plt.title(\"% error per batch\")\n",
    "plt.ylim((0, 40))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "940e34ce3f8e8fda083b4ce6ce11a66042581662800fc131ee85ee96d7946fe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
